{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910c2b25-dcee-410b-9270-cc84d79c496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068cc579-05bd-4385-8263-ef1b3457c0d6",
   "metadata": {},
   "source": [
    "### homework_ex2_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4654fb-6aa7-42c4-b92d-d110abb02978",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../data/ex2data1.txt\", names=['exam1', 'exam2', 'accepted'])\n",
    "X1 = np.array(data1.iloc[:, 0:-1])\n",
    "y1 = np.array(data1.iloc[:, -1]).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe751b22-4da7-48dd-94de-505311a9c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, num_inputs, lr=0.01, batch_size=32, num_epochs=200000):\n",
    "        self.w = torch.zeros((num_inputs, 1), requires_grad=True)\n",
    "        self.b = torch.zeros(1, requires_grad=True)\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.params = [self.w, self.b]\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "\n",
    "    def net(self, X):\n",
    "        \"\"\"逻辑回归模型\"\"\"\n",
    "        return torch.matmul(X, self.w) + self.b\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"小批量随机梯度下降\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for param in self.params:\n",
    "                param -= self.lr * param.grad / self.batch_size\n",
    "                param.grad.zero_()\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for X, y in self.data_iter(self.batch_size, features, labels):\n",
    "                logits = self.net(X)\n",
    "                l = self.loss_fn(torch.sigmoid(logits), y)\n",
    "                l.backward()\n",
    "                self.sgd()\n",
    "            if (epoch + 1) % 20000 == 0:\n",
    "                with torch.no_grad():\n",
    "                    train_l = self.loss_fn(torch.sigmoid(self.net(features)), labels)\n",
    "                    print(f\"Epoch {epoch + 1}, Loss: {train_l.item()}\")  # 直接使用 .item()\n",
    "\n",
    "    @staticmethod\n",
    "    def data_iter(batch_size, features, labels):\n",
    "        \"\"\"数据迭代器\"\"\"\n",
    "        num_examples = len(features)\n",
    "        indices = list(range(num_examples))\n",
    "        random.shuffle(indices)\n",
    "        for i in range(0, num_examples, batch_size):\n",
    "            batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])\n",
    "            yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157244e5-9412-4951-a0b4-20765057d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20000, Loss: 0.5374067425727844\n",
      "Epoch 40000, Loss: 0.4680849313735962\n",
      "Epoch 60000, Loss: 0.42477360367774963\n",
      "Epoch 80000, Loss: 0.3883751928806305\n",
      "Epoch 100000, Loss: 0.3723139464855194\n",
      "Epoch 120000, Loss: 0.34814947843551636\n",
      "Epoch 140000, Loss: 0.35725048184394836\n",
      "Epoch 160000, Loss: 0.3253430128097534\n",
      "Epoch 180000, Loss: 0.3102661371231079\n",
      "Epoch 200000, Loss: 0.2988196313381195\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "features = torch.tensor(X1, dtype=torch.float32)\n",
    "labels = torch.tensor(y1, dtype=torch.float32)\n",
    "\n",
    "model = LogisticRegression(num_inputs=features.shape[1])\n",
    "model.fit(features, labels)\n",
    "\n",
    "threshold = 0.5\n",
    "with torch.no_grad():\n",
    "    logits = model.net(features)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs >= threshold).float()\n",
    "    correct = preds.eq(labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy_torch = correct / total\n",
    "    print(f'Accuracy: {accuracy_torch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c158d4a-3560-4ef5-b33e-baddab584341",
   "metadata": {},
   "source": [
    "### homework_ex2_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfbf5ae-18dd-4661-aa9d-db133b3719b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"../data/ex2data2.txt\", names=['test1', 'test2', 'accepted'])\n",
    "X2 = np.array(data2.iloc[:, 0:-1])\n",
    "y2 = np.array(data2.iloc[:, -1]).reshape(-1, 1)\n",
    "\n",
    "def polynomial_feature_map(X, max_degree=6):\n",
    "    n_samples, n_features = X.shape\n",
    "    features = []\n",
    "    for degree in range(1, max_degree + 1):\n",
    "        for items in itertools.combinations_with_replacement(range(n_features), degree):\n",
    "            features.append(np.prod(X[:, items], axis=1))\n",
    "    features.append(np.ones(n_samples))\n",
    "    return np.column_stack(features)\n",
    "\n",
    "X_map = polynomial_feature_map(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1dc236c-4594-47ab-966b-20c6057406be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "    @staticmethod\n",
    "    def data_iter(features, labels, batch_size=16):\n",
    "        num_examples = len(features)\n",
    "        indices = list(range(num_examples))\n",
    "        random.shuffle(indices)\n",
    "        for i in range(0, num_examples, batch_size):\n",
    "            batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)], dtype=torch.long)\n",
    "            yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123dd15e-3534-49e2-9085-22e60e0e45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10000/100000, Loss: 0.3093\n",
      "Epoch 20000/100000, Loss: 0.3018\n",
      "Epoch 30000/100000, Loss: 0.2985\n",
      "Epoch 40000/100000, Loss: 0.2965\n",
      "Epoch 50000/100000, Loss: 0.2949\n",
      "Epoch 60000/100000, Loss: 0.2937\n",
      "Epoch 70000/100000, Loss: 0.2925\n",
      "Epoch 80000/100000, Loss: 0.2916\n",
      "Epoch 90000/100000, Loss: 0.2907\n",
      "Epoch 100000/100000, Loss: 0.2899\n",
      "Accuracy: 0.864406779661017\n"
     ]
    }
   ],
   "source": [
    "features = torch.tensor(X_map, dtype=torch.float32)\n",
    "labels = torch.tensor(y2, dtype=torch.float32)\n",
    "model = LogisticRegression(in_features=features.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for X, y in model.data_iter(features, labels):\n",
    "        output = model(X)\n",
    "        y = y.reshape(-1, 1)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        if (epoch + 1) % 10000 == 0:\n",
    "            train_l = criterion(model(features), labels)\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_l:.4f}')\n",
    "\n",
    "threshold = 0.5\n",
    "with torch.no_grad():\n",
    "    probs = model(features).squeeze()\n",
    "    preds = (probs >= threshold).float()\n",
    "    labels = labels.squeeze()\n",
    "    correct = preds.eq(labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy_torch = correct / total\n",
    "    print(f'Accuracy: {accuracy_torch}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "llama_factory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
