{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b940a628-ea61-4d8e-ba0f-814fb8a0b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa10ba69-9a0c-486e-8112-ab94d6b1a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\"../data/ex3data1.mat\")\n",
    "raw_X = data['X']\n",
    "raw_y = data['y']\n",
    "raw_y[raw_y == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bc17ba-beaa-456b-a459-77e7305f38e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 400])\n",
      "torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(raw_X, raw_y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64).flatten()\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64).flatten()\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"{X.shape}\")\n",
    "    print(f\"{y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2df6b55-3c2a-4640-b16a-3432a309fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(20*20, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "        # 使用 Xavier 初始化权重\n",
    "        for layer in self.linear_relu_stack:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_normal_(layer.weight, gain=1.414)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60feb523-f065-4ce5-8e5a-ad6b9b98aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c554e0e9-fa35-4933-906e-0b3bd0b65c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84eaa91-881b-429f-9f33-33b6b5a6dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return f\"Test Error: \\n  Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd174bfe-4b88-4b31-be65-ab79cabd5599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 \n",
      "-------------------------------\n",
      "Test Error: \n",
      "  Accuracy: 74.9%, Avg loss: 1.373604 \n",
      "\n",
      "Epoch 40 \n",
      "-------------------------------\n",
      "Test Error: \n",
      "  Accuracy: 81.2%, Avg loss: 0.994641 \n",
      "\n",
      "Epoch 60 \n",
      "-------------------------------\n",
      "Test Error: \n",
      "  Accuracy: 83.5%, Avg loss: 0.811205 \n",
      "\n",
      "Epoch 80 \n",
      "-------------------------------\n",
      "Test Error: \n",
      "  Accuracy: 84.5%, Avg loss: 0.711227 \n",
      "\n",
      "Epoch 100 \n",
      "-------------------------------\n",
      "Test Error: \n",
      "  Accuracy: 84.9%, Avg loss: 0.652351 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    str_info = test(test_dataloader, model, loss_fn)\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {(epoch + 1)} \\n-------------------------------\")\n",
    "        print(str_info)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec58b760-1fe3-4d6f-b466-3e1ec92fd303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"1\", Actual: \"1\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "random_idx = torch.randint(len(x_train_tensor), (1,)).item()\n",
    "\n",
    "x, y = x_train_tensor[random_idx], y_train_tensor[random_idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    x = x.reshape(1, -1)\n",
    "    pred = model(x)\n",
    "    predicted, actual = pred[0].argmax(0), y\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "\n",
    "x_image = x.cpu().numpy().squeeze()\n",
    "x_image = x_image.reshape(20, 20)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(x_image.transpose(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "llama_factory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
